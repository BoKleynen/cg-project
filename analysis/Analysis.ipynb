{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "250a13b6-0c66-49ea-ab8c-734d8063ccfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "NANOS_PER_SEC = 1_000_000_000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0b3e7b0-1eb8-4050-a9e3-0e33faaa5d64",
   "metadata": {},
   "source": [
    "# Splitting Heuristics\n",
    "\n",
    "## Uniformly distributed spheres\n",
    "\n",
    "First we want to get a general impression of how the BVH will behave when performing ray intersection querries depending on which heuristic was used to construct it. To this end spheres with an equal radius R, are placed uniformly in a unit kube centered around (0, 0, -1). The radius is chosen so that the average volume filled with spheres remains constant, this is done to prevent spheres from overlapping too much.\n",
    "\n",
    "Since the scene is uniform, I expect that all heuristics will be quite close to eachother, with the SAH leading slightly because it has a superior stopping criteria based on a cost metric. Object median split's and space median split's stopping criteria depends only on the amount of objects left or the inability to partition the remaining objects.\n",
    "\n",
    "In an ideal case where no bounding boxes overlap and the BVH is a full tree the amount of intersection tests can be calculated as nb_pixels * 2 * log2(N), the 2 comes from the fact that at each level 2 bounbing boxes have to be tested."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1490ac67-44eb-4be8-a617-d0ea5cf8b88c",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_uniform_position.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristisc_equal_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fe5876e7-be0a-43f8-b099-84f752b7d876",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "The graph does show indeed that all splitting heuristics constructs BVHs that are quite similar to eachother in terms of the amount of intersection tests needed to render the scene, with the SAH slightly better. Another thing worth noting that was quite unexpected is that the standard deviation of object median split is so high.\n",
    "\n",
    "This graph also shows that on average the required intersection tests is still an order of magnitude greate than what would be expected in an ideal scenario, this can be explained by the fact that in this experiment bounding boxes will overlap.\n",
    "\n",
    "When adding the amount of intersection tests that would be required by a naive approach to the graphs, it can be seen that this difference in negligible compared to the speedup from use a BVH."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19706c1d-410e-4be3-ad4b-1f4f7bdee212",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_uniform_position.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        naive = 640 * 640 * nb_spheres\n",
    "        ax.plot(nb_spheres, naive, label=\"naieve\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristisc_equal_spheres_uniform_position_with_naive.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1115266-f19b-4dad-a8b7-27608d2cefbe",
   "metadata": {},
   "source": [
    "The amount of internal nodes is O(N)\n",
    "\n",
    "## Time complexities\n",
    "\n",
    "### SAH\n",
    "\n",
    "In the best case the shapes are split into 2 equal parts with each partitioning:\n",
    "\n",
    "n + 2 n/2 + 4 n/4 + ... + log2(n) n/log2(n) = O(n log2(n))\n",
    "\n",
    "In the worst case the nodes are partitioned in a set of length one and a set of length n-1:\n",
    "\n",
    "n + (n-1) + (n-2) + ... + 2 = n(n + 1)/2 = O(n^2)\n",
    "\n",
    "### Space median split\n",
    "\n",
    "Complexity is also dominated by the partitioning, so idem SAH\n",
    "\n",
    "### Object median split\n",
    "\n",
    "The shapes are always split into 2 equal halves, so we get a full binary tree, at each internal node the remaining centroings have to be sorted (implemented with Pattern-defeating quicksort), which is O(n log2(n)):\n",
    "\n",
    "n log2(n) + 2 n/2 log2(n/2)  + 4 n/4 log2(n/4) + ... + log2(n) n/log2(n) log2(n/log2(n))\n",
    "\n",
    "= n log2(n) + [n log2(n) - 1] + [n log2(n) - 2] + ... + [n log2(n) - log2(log2(n))]\n",
    "\n",
    "= O(n log2(n)^2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b641a1c8-2667-415e-acf0-1bb138129587",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_uniform_position_time.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=False, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, durations) in sorted(data['results'].items()):    \n",
    "        results = [np.array([(d[\"secs\"] * NANOS_PER_SEC + d[\"nanos\"]) / 1000000.0 for d in ds]) for ds in durations]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].plot(nb_spheres, averages / nb_spheres, label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"world build time[ms]\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"log\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "#         plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c078009-33cf-474f-9e60-29ea5f56afb2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_uniform_spheres_uniform_position.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0b34352-7731-4942-bcf7-7d101ff618e2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_uniform_spheres_uniform_position_time.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, durations) in sorted(data['results'].items()):\n",
    "        results = [np.array([(d[\"secs\"] * NANOS_PER_SEC + d[\"nanos\"]) / 1000000.0 for d in ds]) for ds in durations]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"world build time[ms]\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "#         plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287424b7-4152-4f64-baa2-0da41e780429",
   "metadata": {},
   "source": [
    "## Non-uniformly distributed spheres"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf3c1aa2-93f4-4d95-9ca6-a7975d7e6697",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_normal_yz.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Normal distributed spheres along y, z and uniform along x with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristics_equal_spheres_normal_yz.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad3be1cf-8b5f-4226-97cf-95ce61a095d2",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_normal_yz_time.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, durations) in sorted(data['results'].items()):    \n",
    "        results = [np.array([(d[\"secs\"] * NANOS_PER_SEC + d[\"nanos\"]) / 1000000.0 for d in ds]) for ds in durations]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"world build time[ms]\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "#         plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e78841ff-d3b1-4efd-80c4-ce1967f0a247",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_uniform_yz.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Normal distributed spheres along y, z and uniform along x with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristics_equal_spheres_uniform_yz.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71015493-413a-4d0f-a03c-5c0e92e7c0f3",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_uniform_yz_time.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, durations) in sorted(data['results'].items()):    \n",
    "        results = [np.array([(d[\"secs\"] * NANOS_PER_SEC + d[\"nanos\"]) / 1000000.0 for d in ds]) for ds in durations]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"world build time[ms]\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "#         plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a1baba0-5140-43b9-9241-5989c6ebad22",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_beta_corners.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Spheres in corners with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        plt.savefig(\"../report/plots/splitting_heuristics_equal_spheres_beta_corners.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "866145ee-242a-4fd1-97d1-75a27e845df8",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_beta_corners_time.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "#     fig.suptitle(\"Uniformly distributed spheres with a uniformly distributed radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, durations) in sorted(data['results'].items()):    \n",
    "        results = [np.array([(d[\"secs\"] * NANOS_PER_SEC + d[\"nanos\"]) / 1000000.0 for d in ds]) for ds in durations]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"world build time[ms]\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "#         plt.savefig(\"../report/plots/splitting_heuristisc_uniform_spheres_uniform_position.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e44cdff-6879-4163-b388-8a0fbda21c7b",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_beta_corners2.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "    fig.suptitle(\"Spheres in corners with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        # plt.savefig('../experiments/results/plots/compare_splitting_heuristics2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9fcaac9-c977-4ad1-9e00-7161e601cd68",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/splitting_heuristics_equal_spheres_beta_x.json\") as f:\n",
    "    data = json.load(f)\n",
    "    \n",
    "    nb_spheres = np.array(data['nb_objects'])\n",
    "    \n",
    "    fig, axs = plt.subplots(1, 2, sharey=True, figsize=(15, 7))\n",
    "    fig.suptitle(\"Uniformly distributed spheres with an equal radius\")\n",
    "\n",
    "        \n",
    "    for (splitting_heuristic, intersection_tests) in sorted(data['results'].items()):        \n",
    "        results = [np.array(k) for k in intersection_tests]\n",
    "        averages = np.array([np.average(res) for res in results])\n",
    "        stds = np.array([np.std(res) for res in results])\n",
    "        \n",
    "        if \"Alternate\" in splitting_heuristic:\n",
    "            axs[0].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "        else:\n",
    "            axs[1].errorbar(nb_spheres, averages, yerr=stds, fmt='-o', label=splitting_heuristic.split(\" \")[1])\n",
    "       \n",
    "    axs[0].set(ylabel=\"intersection tests\", title=\"Alternating axis\")\n",
    "    axs[1].set(title=\"Longest axis\")\n",
    "    \n",
    "    for ax in axs:    \n",
    "        ideal = 640 * 640 * 2 * np.log2(nb_spheres)\n",
    "        ax.plot(nb_spheres, ideal, label=\"ideal\")\n",
    "        \n",
    "        ax.grid(True)\n",
    "        ax.set_yscale(\"linear\")\n",
    "        ax.set_xscale(\"linear\")\n",
    "        ax.set(xlabel=\"spheres\")\n",
    "        ax.legend()\n",
    "        #     plt.savefig('../experiments/results/plots/compare_splitting_heuristics2.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12189ec9-1346-434e-84e2-0b540e8daa9e",
   "metadata": {
    "pycharm": {
     "is_executing": true
    }
   },
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(nrows=1, ncols=2, figsize=(15, 7))\n",
    "    \n",
    "with open(\"../renders/intersection_tests_sah.txt\") as file:\n",
    "    counts = list(map(int, file.read().split(\",\")))\n",
    "    counts = [counts[i:i+640] for i in range(0, len(counts), 640)]\n",
    "    axs[0].imshow(counts, origin=\"lower\", interpolation=\"none\")\n",
    "    axs[0].get_xaxis().set_visible(False)\n",
    "    axs[0].get_yaxis().set_visible(False)\n",
    "    axs[0].set(title=\"Surface area heuristic\")\n",
    "\n",
    "with open(\"../renders/intersection_tests_space_median.txt\") as file:\n",
    "    counts = list(map(int, file.read().split(\",\")))\n",
    "    counts = [counts[i:i+640] for i in range(0, len(counts), 640)]\n",
    "    pcm = axs[1].imshow(counts, origin=\"lower\", interpolation=\"none\")\n",
    "    axs[1].get_xaxis().set_visible(False)\n",
    "    axs[1].get_yaxis().set_visible(False)\n",
    "    axs[1].set(title=\"Space median split\")\n",
    "    \n",
    "    fig.colorbar(pcm, ax=axs, shrink=0.75)\n",
    "    \n",
    "# plt.savefig(\"../experiments/results/plots/splitting_heuristics_equal_spheres_beta_corners_false_color.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f67cbd69-e772-4446-95e5-d35b6d3243a6",
   "metadata": {},
   "source": [
    "# Object instancing\n",
    "\n",
    "## Rendering performance"
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "with open(\"../experiments/results/instanced_intersections.json\") as f1, open(\"../experiments/results/flattened_intersections.json\") as f2:\n",
    "    instanced_data = json.load(f1)\n",
    "    flattened_data = json.load(f2)\n",
    "    \n",
    "    nb_objects = np.array(instanced_data[\"nb_objects\"])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "        \n",
    "    results = [np.array(k) for k in instanced_data[\"results\"][\"Alternate, SurfaceAreaHeuristic(12)\"]]\n",
    "    averages = np.array([np.average(res) for res in results])\n",
    "    stds = np.array([np.std(res) for res in results])\n",
    "    ax.errorbar(nb_objects, averages, yerr=stds, fmt=\"-o\", label=\"instancing\")\n",
    "    \n",
    "    results = [np.array(k) for k in flattened_data[\"results\"][\"Alternate, SurfaceAreaHeuristic(12)\"]]\n",
    "    averages = np.array([np.average(res) for res in results])\n",
    "    stds = np.array([np.std(res) for res in results])\n",
    "    ax.errorbar(nb_objects, averages, yerr=stds, fmt=\"-o\", label=\"triangle soup\")\n",
    "        \n",
    "    ax.set_yscale(\"linear\")\n",
    "    ax.set_xscale(\"linear\")\n",
    "    ax.set(xlabel=\"bunnies\", ylabel=\"intersection tests\")\n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.savefig(\"../experiments/results/plots/instancing_intersection_tests.png\")"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "As we can see from the graph a triangle soup requires slightly less intersection tests when rendering the image. An experiment with significantly more bunnies is required to verify if this gap continues to widen. While performing the experiments for this part I noticed that the time it took to construct the BVH increased significantly, up to the point that it seemed to take longer than the actual rendering. This could be a subject for further testing if I had more time available.\n",
    "\n",
    "## Memory\n",
    "\n",
    "This experiment uses [jemalloc](http://jemalloc.net) to heap memory required to store the world. The amount of allocated heap memory was measured before creating the world and after the world has been created, the difference is then the amount of heap memory used by the world.\n",
    "\n",
    "Because instancing requires very few additional data, just the tranformation matrixes and a pointer to the mesh (which is negligible in comparison to the mesh), I expect that the memory usage will remain relatively constant. Without instancing I expect the memory usage to increase linearly with the amount of \"instances\" in the scene"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbb96a6f-ab68-42dc-918f-e550afb6ee5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"../experiments/results/instanced_memory.json\") as f1, open(\"../experiments/results/flattened_memory.json\") as f2:\n",
    "    instanced_data = json.load(f1)\n",
    "    flattened_data = json.load(f2)\n",
    "    \n",
    "    nb_objects = np.array(instanced_data[\"nb_objects\"])\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_yscale(\"linear\")\n",
    "    ax.set_xscale(\"linear\")\n",
    "    ax.set(xlabel=\"bunnies\", ylabel=\"heap memory[MB]\")\n",
    "        \n",
    "    results = [np.array(k) for k in instanced_data[\"results\"][\"Alternate, SurfaceAreaHeuristic(12)\"]]\n",
    "    averages = np.array([np.average(res) for res in results]) / 1000000\n",
    "    stds = np.array([np.std(res) for res in results]) / 1000000\n",
    "    ax.errorbar(nb_objects, averages, yerr=stds, fmt=\"-o\", label=\"instancing\")\n",
    "    \n",
    "    results = [np.array(k) for k in flattened_data[\"results\"][\"Alternate, SurfaceAreaHeuristic(12)\"]]\n",
    "    averages = np.array([np.average(res) for res in results]) / 1000000\n",
    "    stds = np.array([np.std(res) for res in results]) / 1000000\n",
    "    ax.errorbar(nb_objects, averages, yerr=stds, fmt=\"-o\", label=\"triangle soup\")\n",
    "        \n",
    "    ax.grid(True)\n",
    "    ax.legend()\n",
    "    plt.savefig(\"../experiments/results/plots/instancing_heap_memory.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a53e9e01-ed0c-40ad-b67f-79063e19f7eb",
   "metadata": {
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "Besides the high BVH construction times and the very high memory usage, there is another downside to not using instancing, although this one can be quite subjective. With the use of instancing you can easily compose a scene programatically from smaller components, this proved to be quite cumbersome in my implementation (this approach was used to set up the experiment), another way to resolve this issue could be to by introducing an additional translation step that flattens a scene graph. This last approach has the added drawback that almost all data structure used in the scene graph have to be cloneable (implement the Clone trait in Rust, this won't be covered further here), which again wasn't the case in my implementation as it used instancing from the start.\n",
    "\n",
    "Because of all these benefits instancing is a sane default. For very large scenes that we want to render from multiple camera perspectives, flattening the scene graph might be beneficial if the the speedup outwheighs the increased BVH construction time."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}